version: '3.8'

services:
  archiver:
    build:
      context: ./serve
      dockerfile: Dockerfile.archiver
    container_name: heat-archiver
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - type: bind
        source: ./serve/checkpoints.pth
        target: /home/heat/checkpoints.pth
      - type: bind
        source: ./model-store
        target: /home/heat/model-store
    working_dir: /home/heat
    command: torch-model-archiver --model-name heat --version 1.0 --model-file heat.py --serialized-file checkpoint.pth --extra-files models.zip,datasets.zip,metrics.zip,utils.zip,infer.py --handler serve/handler.py --requirements-file requirements.txt --export-path model-store


  server:
    build:
      context: ./serve
      dockerfile: Dockerfile.server
    container_name: heat-server
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - type: bind
        source: ./model-store
        target: /home/heat/model-store
    ports:
      - "7070:7070"
      - "7071:7071"
      - "8000:8000"
      - "8001:8001"
      - "8080:8080"
      - "8081:8081"
      - "8082:8082"
    entrypoint: [bash, -c]
    command: ["torchserve --start --ncs --model-store /home/heat/model-store --models heat=heat.mar --ts-config /home/heat/config.properties & tail -f /dev/null"]


